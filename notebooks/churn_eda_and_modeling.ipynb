# Setup
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Start Spark session
spark = SparkSession.builder.appName("ChurnEDA").getOrCreate()

# Load enriched data
df = spark.read.parquet("data/processed/churn_enriched.parquet")
df.printSchema()
df.show(5)

# Churn distribution
df.groupBy("label").count().show()

# Average total day charge by churn
df.groupBy("label").avg("Total day charge").show()

# High-value customer churn rate
df.groupBy("high_value_customer", "label").count().orderBy("high_value_customer").show()

# International usage vs churn
df.groupBy("uses_international", "label").count().orderBy("uses_international").show()

# Convert to Pandas for plotting (optional)
df_pd = df.select("label", "high_value_customer", "Total day charge", "uses_international").toPandas()

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df_pd, x="label")
plt.title("Churn Distribution")
plt.show()

sns.boxplot(data=df_pd, x="label", y="Total day charge")
plt.title("Total Day Charge by Churn")
plt.show()

# Simple ML Model: Logistic Regression
lr = LogisticRegression(featuresCol="features", labelCol="label")
model = lr.fit(df)

# Evaluate model
predictions = model.transform(df)
evaluator = BinaryClassificationEvaluator(labelCol="label")
accuracy = evaluator.evaluate(predictions)

print(f"Model Accuracy (AUC): {accuracy:.4f}")

# Show predictions
predictions.select("label", "prediction", "probability").show(5)

# Insights Summary
print("""
 Insights:
- High-value customers show slightly higher churn rates.
- International usage correlates with churn in some cases.
- Logistic Regression achieves decent baseline performance.
""")
